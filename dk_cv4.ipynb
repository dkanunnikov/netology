{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dk_cv4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/dkanunnikov/netology/blob/master/dk_cv4.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "HA519C5r-fsN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Yelp Restaurant Photo Classification"
      ]
    },
    {
      "metadata": {
        "id": "ck6-98ZC-2jT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Описание задания:\n",
        "Предсказание тегов ресторанов по фотографиям\n",
        "Обучить модель предсказания тегов ресторанов по набору фото. Исходные данные и валидация на Kaggle в рамках контеста Yelp Restaurant Photo Classification. Шаблон ноутбука для подготовки решения: yelp-hw.ipynb .\n",
        "Решение необходимо прислать в виде ссылки на ipython-ноутбука с указанием значения метрики на Leaderboard. Задание засчитывается при значение метрики на Leaderboard больше 0.7."
      ]
    },
    {
      "metadata": {
        "id": "TVo9tnUA-fsN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/c/yelp-restaurant-photo-classification"
      ]
    },
    {
      "metadata": {
        "id": "3z78EWB_yRtW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "73011ac1-7feb-46c0-8ab1-ca59bd167cea"
      },
      "cell_type": "code",
      "source": [
        "!pip install keras --upgrade\n",
        "!pip install keras_applications --upgrade\n",
        "!pip install kaggle\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing==1.0.2 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications==1.0.4 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.4)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\n",
            "Requirement already up-to-date: keras_applications in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications) (1.14.5)\n",
            "Requirement already satisfied, skipping upgrade: keras>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from keras_applications) (2.2.2)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.6->keras_applications) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing==1.0.2 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.6->keras_applications) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.6->keras_applications) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.6->keras_applications) (0.19.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.4.6)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.24.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.4.16)\n",
            "Requirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_o8KSReT-fsN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#from tensorflow.contrib import keras\n",
        "import keras\n",
        "from keras.models import Model, Sequential\n",
        "from keras.applications.xception import Xception, preprocess_input\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Concatenate\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "preprocess_input = keras.applications.vgg16.preprocess_input\n",
        "VGG16 = keras.applications.VGG16\n",
        "\n",
        "IMG_SIZE = (224, 224)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0vw4rS6p_fup",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle-cli > /dev/null\n",
        "!rm -rf train_photos && rm -rf test_photos > /dev/null && rm -rf train > /dev/null && rm -rf test > /dev/null\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2M8pvVT9hkiJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0a16ed1f-1f3e-4f33-c30f-3577af0f0e3e"
      },
      "cell_type": "code",
      "source": [
        "!kaggle  config  set  -n  path  -v  /content"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\r\n",
            "  File \"/usr/local/bin/kaggle\", line 7, in <module>\r\n",
            "    from kaggle.cli import main\r\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/__init__.py\", line 23, in <module>\r\n",
            "    api.authenticate()\r\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/api/kaggle_api_extended.py\", line 109, in authenticate\r\n",
            "    self._load_config(config_data)\r\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/api/kaggle_api_extended.py\", line 151, in _load_config\r\n",
            "    raise ValueError('Error: Missing %s in configuration.' % item)\r\n",
            "ValueError: Error: Missing username in configuration.\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WnZth6r0_7DY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "46f0174f-8d1c-4fa3-f90d-33df72f25598"
      },
      "cell_type": "code",
      "source": [
        "!kg  download -u webotdel@mail.ru  -p 64136413L   -c yelp-restaurant-photo-classification -f train_photos.tgz"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py:37: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\r\n",
            "\r\n",
            "The code that caused this warning is on line 37 of the file /usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\r\n",
            "\r\n",
            "  response.content, **soup_config)\r\n",
            "downloading https://www.kaggle.com/c/yelp-restaurant-photo-classification/download/train_photos.tgz\r\n",
            "\n",
            "train_photos.tgz already downloaded !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZWUNoiZFALsv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "3538aca1-f10d-4f4f-ec80-f904cebb39eb"
      },
      "cell_type": "code",
      "source": [
        "!kg  download -u *** -p ***  -c yelp-restaurant-photo-classification -f test_photos.tgz"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py:37: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\r\n",
            "\r\n",
            "The code that caused this warning is on line 37 of the file /usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\r\n",
            "\r\n",
            "  response.content, **soup_config)\r\n",
            "downloading https://www.kaggle.com/c/yelp-restaurant-photo-classification/download/test_photos.tgz\r\n",
            "\n",
            "test_photos.tgz already downloaded !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TZ46TfFSAU6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "38f97cf8-a8ec-4ace-883b-dec11f1f0816"
      },
      "cell_type": "code",
      "source": [
        "!kg  download -u *** -p ***  -c yelp-restaurant-photo-classification -f train.csv.tgz"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py:37: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\r\n",
            "\r\n",
            "The code that caused this warning is on line 37 of the file /usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\r\n",
            "\r\n",
            "  response.content, **soup_config)\r\n",
            "downloading https://www.kaggle.com/c/yelp-restaurant-photo-classification/download/train.csv.tgz\r\n",
            "\n",
            "train.csv.tgz already downloaded !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CRGNxoA8AhOv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "52a2e89a-6612-4f44-de82-f66ce417dd90"
      },
      "cell_type": "code",
      "source": [
        "!kg  download -u *** -p ***  -c yelp-restaurant-photo-classification -f train_photo_to_biz_ids.csv.tgz"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py:37: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\r\n",
            "\r\n",
            "The code that caused this warning is on line 37 of the file /usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\r\n",
            "\r\n",
            "  response.content, **soup_config)\r\n",
            "downloading https://www.kaggle.com/c/yelp-restaurant-photo-classification/download/train_photo_to_biz_ids.csv.tgz\r\n",
            "\n",
            "train_photo_to_biz_ids.csv.tgz already downloaded !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kwypEwuZAmiX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "208a0342-7979-48e4-bc9a-5fb8055ccf42"
      },
      "cell_type": "code",
      "source": [
        "!kg  download -u *** -p ***  -c yelp-restaurant-photo-classification -f test_photo_to_biz.csv.tgz"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py:37: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\r\n",
            "\r\n",
            "The code that caused this warning is on line 37 of the file /usr/local/lib/python3.6/dist-packages/mechanicalsoup/browser.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\r\n",
            "\r\n",
            "  response.content, **soup_config)\n",
            "downloading https://www.kaggle.com/c/yelp-restaurant-photo-classification/download/test_photo_to_biz.csv.tgz\n",
            "\n",
            "test_photo_to_biz.csv.tgz already downloaded !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RfuVrJC1Jp-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -zxvf train_photos.tgz > /dev/null && tar -zxvf test_photos.tgz > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OXRzzvoMcD6b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -zxvf train.csv.tgz > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_biSK0v-cJW1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -zxvf train_photo_to_biz_ids.csv.tgz > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lT8bpl6HcLfF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -zxvf test_photo_to_biz.csv.tgz > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aQm-1ZnHUUY1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "dff1e885-3f0d-47ea-e478-e102861fc057"
      },
      "cell_type": "code",
      "source": [
        "!ls  -l"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 13963456\r\n",
            "drwxr-xr-x 3 root root        4096 Aug  3 16:51 datalab\r\n",
            "-rw-r--r-- 1 root root      174767 Aug  8 11:12 submission.csv\r\n",
            "drwxr-xr-x 2  501 staff   14315520 Oct 30  2015 test_photos\r\n",
            "-rw-r--r-- 1 root root  7102584231 Aug  8 08:33 test_photos.tgz\r\n",
            "-rw-r--r-- 1  504 staff   15193591 Dec 17  2015 test_photo_to_biz.csv\r\n",
            "-rw-r--r-- 1 root root     5019061 Aug  8 08:33 test_photo_to_biz.csv.tgz\r\n",
            "-rw-r--r-- 1  501 staff      28760 Dec 15  2015 train.csv\r\n",
            "-rw-r--r-- 1 root root        7287 Aug  8 08:33 train.csv.tgz\r\n",
            "drwxr-xr-x 2  501 staff   14131200 Oct 30  2015 train_photos\r\n",
            "-rw-r--r-- 1 root root  7026724672 Aug  8 08:29 train_photos.tgz\r\n",
            "-rw-r----- 1  501 staff    2698404 Dec 14  2015 train_photo_to_biz_ids.csv\r\n",
            "-rw-r--r-- 1 root root     1171455 Aug  8 08:33 train_photo_to_biz_ids.csv.tgz\r\n",
            "-rw-r--r-- 1 root root   116496080 Aug  8 08:40 yelp_weights.h5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fgOagVWw-fsN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Загружаем разметку"
      ]
    },
    {
      "metadata": {
        "id": "AFN9t3UY-fsN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_biz_df = pd.read_csv('train.csv')\n",
        "train_photos_df = pd.read_csv('train_photo_to_biz_ids.csv')\n",
        "data_df = train_photos_df.merge(train_biz_df)\n",
        "\n",
        "data_df.dropna(inplace=True)\n",
        "\n",
        "test_photos_df = pd.read_csv('test_photo_to_biz.csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VzCLA0Iq-fsd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_image(path, img_id, img_size=(224, 224)):\n",
        "    img = cv2.imread(os.path.join(path, '%s.jpg' % img_id))[:,:,::-1]\n",
        "    img = preprocess_input(img.astype(np.float32))\n",
        "    return cv2.resize(img, img_size)\n",
        "\n",
        "def to_dense(labels):\n",
        "    result = [0] * 9\n",
        "    for i in labels:\n",
        "        result[i] = 1.\n",
        "    return result\n",
        "\n",
        "def train_generator(df, img_size=(224, 224), batch_size=32):\n",
        "    while True:\n",
        "        df = df.sample(frac=1).reset_index(drop=True)\n",
        "        for i in range(0, len(df) // batch_size * batch_size, batch_size):\n",
        "            X, y = [], []\n",
        "            for _, row in df[i:i + batch_size].iterrows():\n",
        "                X.append(get_image('train_photos', row['photo_id'], img_size))\n",
        "                y.append(to_dense(map(int, str(row['labels']).split())))\n",
        "            y = np.array(y)\n",
        "            yield np.array(X), [y[:, i] for i in range(9)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nIWIOAcr-fsd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: build CNN model\n",
        "# TODO: train CNN model using train_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ul7hqU7Mi1UM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "base_model = VGG16(\n",
        "    include_top = False,\n",
        "    weights = 'imagenet',\n",
        "    input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "    pooling = 'avg'\n",
        ")\n",
        "\n",
        "checkout = ModelCheckpoint('yelp_weights.h5', save_best_only=True, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jh8pP9HKMWqo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#base_model = InceptionV3(\n",
        "#    include_top = False,\n",
        "#    weights = 'imagenet',\n",
        "#    input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "#    pooling = 'avg'\n",
        "#)\n",
        "\n",
        "#base_model = Xception(include_top = False,\n",
        "#                   weights = 'imagenet',\n",
        "#                   input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "#                   pooling = 'avg'\n",
        "#           )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qofcydOyMZ4M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# фиксируем все веса предобученной сети\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mlplUgzFM2Cd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "6397d7a8-3e97-47ca-8ee1-3d7c6483d17b"
      },
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 512)               0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Gkl4uK8MeQ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "predictions = []\n",
        "for i in range(9):\n",
        "    x0 = Dense(128, activation='relu')(x)\n",
        "    x0 = Dropout(0.5)(x0)\n",
        "    x0 = Dense(1, activation='sigmoid')(x0)\n",
        "    predictions.append(x0)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jgUtBbJ2jGAD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(data_df, test_size=0.01, random_state=123)\n",
        "test_X, test_Y = next(train_generator(test_df, batch_size = len(test_df)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_IWH4CjjKX_2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm yelp_weights.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oIfeyg3ujJSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "48acf541-5a00-4089-a305-457f75fc081d"
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "        train_generator(train_df, batch_size = 100),\n",
        "        steps_per_epoch=100,\n",
        "        epochs=10,\n",
        "        validation_data=(test_X, test_Y),\n",
        "        callbacks=[checkout]\n",
        ")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 153s 2s/step - loss: 9.8834 - dense_20_loss: 1.5234 - dense_22_loss: 0.9963 - dense_24_loss: 1.0207 - dense_26_loss: 1.1845 - dense_28_loss: 0.9369 - dense_30_loss: 1.3030 - dense_32_loss: 0.8530 - dense_34_loss: 1.0120 - dense_36_loss: 1.0537 - dense_20_acc: 0.7131 - dense_22_acc: 0.6435 - dense_24_acc: 0.6622 - dense_26_acc: 0.5149 - dense_28_acc: 0.6386 - dense_30_acc: 0.6986 - dense_32_acc: 0.7497 - dense_34_acc: 0.6398 - dense_36_acc: 0.6233 - val_loss: 4.9500 - val_dense_20_loss: 0.4891 - val_dense_22_loss: 0.5624 - val_dense_24_loss: 0.5370 - val_dense_26_loss: 0.6939 - val_dense_28_loss: 0.5641 - val_dense_30_loss: 0.5080 - val_dense_32_loss: 0.4265 - val_dense_34_loss: 0.5761 - val_dense_36_loss: 0.5929 - val_dense_20_acc: 0.7762 - val_dense_22_acc: 0.7106 - val_dense_24_acc: 0.7276 - val_dense_26_acc: 0.5494 - val_dense_28_acc: 0.7080 - val_dense_30_acc: 0.7570 - val_dense_32_acc: 0.8150 - val_dense_34_acc: 0.7089 - val_dense_36_acc: 0.6952\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.94998, saving model to yelp_weights.h5\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 135s 1s/step - loss: 5.1669 - dense_20_loss: 0.5093 - dense_22_loss: 0.5942 - dense_24_loss: 0.5664 - dense_26_loss: 0.7010 - dense_28_loss: 0.5901 - dense_30_loss: 0.5288 - dense_32_loss: 0.4704 - dense_34_loss: 0.5947 - dense_36_loss: 0.6120 - dense_20_acc: 0.7726 - dense_22_acc: 0.6914 - dense_24_acc: 0.7124 - dense_26_acc: 0.5346 - dense_28_acc: 0.6999 - dense_30_acc: 0.7490 - dense_32_acc: 0.7910 - dense_34_acc: 0.6922 - dense_36_acc: 0.6842 - val_loss: 4.7730 - val_dense_20_loss: 0.4664 - val_dense_22_loss: 0.5404 - val_dense_24_loss: 0.5173 - val_dense_26_loss: 0.6869 - val_dense_28_loss: 0.5422 - val_dense_30_loss: 0.4819 - val_dense_32_loss: 0.4024 - val_dense_34_loss: 0.5636 - val_dense_36_loss: 0.5720 - val_dense_20_acc: 0.7916 - val_dense_22_acc: 0.7315 - val_dense_24_acc: 0.7383 - val_dense_26_acc: 0.5639 - val_dense_28_acc: 0.7315 - val_dense_30_acc: 0.7660 - val_dense_32_acc: 0.8227 - val_dense_34_acc: 0.7123 - val_dense_36_acc: 0.7063\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.94998 to 4.77304, saving model to yelp_weights.h5\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 134s 1s/step - loss: 4.9557 - dense_20_loss: 0.4906 - dense_22_loss: 0.5768 - dense_24_loss: 0.5330 - dense_26_loss: 0.6971 - dense_28_loss: 0.5635 - dense_30_loss: 0.4932 - dense_32_loss: 0.4395 - dense_34_loss: 0.5758 - dense_36_loss: 0.5863 - dense_20_acc: 0.7801 - dense_22_acc: 0.7040 - dense_24_acc: 0.7404 - dense_26_acc: 0.5330 - dense_28_acc: 0.7179 - dense_30_acc: 0.7622 - dense_32_acc: 0.7939 - dense_34_acc: 0.7009 - dense_36_acc: 0.7033 - val_loss: 4.6778 - val_dense_20_loss: 0.4642 - val_dense_22_loss: 0.5321 - val_dense_24_loss: 0.5009 - val_dense_26_loss: 0.6835 - val_dense_28_loss: 0.5270 - val_dense_30_loss: 0.4692 - val_dense_32_loss: 0.3928 - val_dense_34_loss: 0.5480 - val_dense_36_loss: 0.5600 - val_dense_20_acc: 0.7869 - val_dense_22_acc: 0.7340 - val_dense_24_acc: 0.7498 - val_dense_26_acc: 0.5784 - val_dense_28_acc: 0.7396 - val_dense_30_acc: 0.7818 - val_dense_32_acc: 0.8240 - val_dense_34_acc: 0.7285 - val_dense_36_acc: 0.7008\n",
            "\n",
            "Epoch 00003: val_loss improved from 4.77304 to 4.67779, saving model to yelp_weights.h5\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 134s 1s/step - loss: 4.8458 - dense_20_loss: 0.4938 - dense_22_loss: 0.5585 - dense_24_loss: 0.5246 - dense_26_loss: 0.6881 - dense_28_loss: 0.5558 - dense_30_loss: 0.4704 - dense_32_loss: 0.4185 - dense_34_loss: 0.5552 - dense_36_loss: 0.5808 - dense_20_acc: 0.7685 - dense_22_acc: 0.7166 - dense_24_acc: 0.7434 - dense_26_acc: 0.5450 - dense_28_acc: 0.7191 - dense_30_acc: 0.7677 - dense_32_acc: 0.8070 - dense_34_acc: 0.7232 - dense_36_acc: 0.7085 - val_loss: 4.6159 - val_dense_20_loss: 0.4591 - val_dense_22_loss: 0.5267 - val_dense_24_loss: 0.4907 - val_dense_26_loss: 0.6772 - val_dense_28_loss: 0.5342 - val_dense_30_loss: 0.4589 - val_dense_32_loss: 0.3864 - val_dense_34_loss: 0.5388 - val_dense_36_loss: 0.5440 - val_dense_20_acc: 0.7899 - val_dense_22_acc: 0.7323 - val_dense_24_acc: 0.7592 - val_dense_26_acc: 0.5742 - val_dense_28_acc: 0.7174 - val_dense_30_acc: 0.7809 - val_dense_32_acc: 0.8299 - val_dense_34_acc: 0.7285 - val_dense_36_acc: 0.7246\n",
            "\n",
            "Epoch 00004: val_loss improved from 4.67779 to 4.61588, saving model to yelp_weights.h5\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 134s 1s/step - loss: 4.7617 - dense_20_loss: 0.4785 - dense_22_loss: 0.5541 - dense_24_loss: 0.5180 - dense_26_loss: 0.6849 - dense_28_loss: 0.5448 - dense_30_loss: 0.4633 - dense_32_loss: 0.4155 - dense_34_loss: 0.5390 - dense_36_loss: 0.5636 - dense_20_acc: 0.7805 - dense_22_acc: 0.7160 - dense_24_acc: 0.7423 - dense_26_acc: 0.5570 - dense_28_acc: 0.7263 - dense_30_acc: 0.7743 - dense_32_acc: 0.8179 - dense_34_acc: 0.7258 - dense_36_acc: 0.7113 - val_loss: 4.5838 - val_dense_20_loss: 0.4562 - val_dense_22_loss: 0.5236 - val_dense_24_loss: 0.4916 - val_dense_26_loss: 0.6758 - val_dense_28_loss: 0.5234 - val_dense_30_loss: 0.4589 - val_dense_32_loss: 0.3758 - val_dense_34_loss: 0.5397 - val_dense_36_loss: 0.5388 - val_dense_20_acc: 0.7903 - val_dense_22_acc: 0.7289 - val_dense_24_acc: 0.7532 - val_dense_26_acc: 0.5916 - val_dense_28_acc: 0.7455 - val_dense_30_acc: 0.7869 - val_dense_32_acc: 0.8329 - val_dense_34_acc: 0.7280 - val_dense_36_acc: 0.7285\n",
            "\n",
            "Epoch 00005: val_loss improved from 4.61588 to 4.58382, saving model to yelp_weights.h5\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 133s 1s/step - loss: 4.7569 - dense_20_loss: 0.4712 - dense_22_loss: 0.5433 - dense_24_loss: 0.5086 - dense_26_loss: 0.6874 - dense_28_loss: 0.5494 - dense_30_loss: 0.4708 - dense_32_loss: 0.4090 - dense_34_loss: 0.5488 - dense_36_loss: 0.5685 - dense_20_acc: 0.7788 - dense_22_acc: 0.7290 - dense_24_acc: 0.7555 - dense_26_acc: 0.5489 - dense_28_acc: 0.7214 - dense_30_acc: 0.7684 - dense_32_acc: 0.8131 - dense_34_acc: 0.7187 - dense_36_acc: 0.7108 - val_loss: 4.5458 - val_dense_20_loss: 0.4496 - val_dense_22_loss: 0.5221 - val_dense_24_loss: 0.4824 - val_dense_26_loss: 0.6754 - val_dense_28_loss: 0.5165 - val_dense_30_loss: 0.4472 - val_dense_32_loss: 0.3741 - val_dense_34_loss: 0.5384 - val_dense_36_loss: 0.5400 - val_dense_20_acc: 0.7992 - val_dense_22_acc: 0.7332 - val_dense_24_acc: 0.7651 - val_dense_26_acc: 0.5895 - val_dense_28_acc: 0.7498 - val_dense_30_acc: 0.7937 - val_dense_32_acc: 0.8376 - val_dense_34_acc: 0.7293 - val_dense_36_acc: 0.7302\n",
            "\n",
            "Epoch 00006: val_loss improved from 4.58382 to 4.54578, saving model to yelp_weights.h5\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 135s 1s/step - loss: 4.7624 - dense_20_loss: 0.4667 - dense_22_loss: 0.5524 - dense_24_loss: 0.5216 - dense_26_loss: 0.6851 - dense_28_loss: 0.5403 - dense_30_loss: 0.4689 - dense_32_loss: 0.4081 - dense_34_loss: 0.5548 - dense_36_loss: 0.5645 - dense_20_acc: 0.7846 - dense_22_acc: 0.7250 - dense_24_acc: 0.7443 - dense_26_acc: 0.5507 - dense_28_acc: 0.7318 - dense_30_acc: 0.7738 - dense_32_acc: 0.8154 - dense_34_acc: 0.7149 - dense_36_acc: 0.7157 - val_loss: 4.5060 - val_dense_20_loss: 0.4479 - val_dense_22_loss: 0.5151 - val_dense_24_loss: 0.4798 - val_dense_26_loss: 0.6722 - val_dense_28_loss: 0.5094 - val_dense_30_loss: 0.4451 - val_dense_32_loss: 0.3751 - val_dense_34_loss: 0.5285 - val_dense_36_loss: 0.5330 - val_dense_20_acc: 0.7894 - val_dense_22_acc: 0.7472 - val_dense_24_acc: 0.7775 - val_dense_26_acc: 0.5904 - val_dense_28_acc: 0.7519 - val_dense_30_acc: 0.7801 - val_dense_32_acc: 0.8414 - val_dense_34_acc: 0.7340 - val_dense_36_acc: 0.7349\n",
            "\n",
            "Epoch 00007: val_loss improved from 4.54578 to 4.50597, saving model to yelp_weights.h5\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 135s 1s/step - loss: 4.6777 - dense_20_loss: 0.4582 - dense_22_loss: 0.5486 - dense_24_loss: 0.4920 - dense_26_loss: 0.6848 - dense_28_loss: 0.5455 - dense_30_loss: 0.4509 - dense_32_loss: 0.4016 - dense_34_loss: 0.5441 - dense_36_loss: 0.5521 - dense_20_acc: 0.7852 - dense_22_acc: 0.7272 - dense_24_acc: 0.7612 - dense_26_acc: 0.5508 - dense_28_acc: 0.7231 - dense_30_acc: 0.7804 - dense_32_acc: 0.8160 - dense_34_acc: 0.7227 - dense_36_acc: 0.7255 - val_loss: 4.4864 - val_dense_20_loss: 0.4500 - val_dense_22_loss: 0.5137 - val_dense_24_loss: 0.4749 - val_dense_26_loss: 0.6707 - val_dense_28_loss: 0.5062 - val_dense_30_loss: 0.4423 - val_dense_32_loss: 0.3719 - val_dense_34_loss: 0.5279 - val_dense_36_loss: 0.5288 - val_dense_20_acc: 0.7916 - val_dense_22_acc: 0.7438 - val_dense_24_acc: 0.7762 - val_dense_26_acc: 0.5887 - val_dense_28_acc: 0.7502 - val_dense_30_acc: 0.7997 - val_dense_32_acc: 0.8419 - val_dense_34_acc: 0.7374 - val_dense_36_acc: 0.7361\n",
            "\n",
            "Epoch 00008: val_loss improved from 4.50597 to 4.48645, saving model to yelp_weights.h5\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 136s 1s/step - loss: 4.6604 - dense_20_loss: 0.4645 - dense_22_loss: 0.5367 - dense_24_loss: 0.4954 - dense_26_loss: 0.6813 - dense_28_loss: 0.5337 - dense_30_loss: 0.4583 - dense_32_loss: 0.3905 - dense_34_loss: 0.5396 - dense_36_loss: 0.5604 - dense_20_acc: 0.7826 - dense_22_acc: 0.7315 - dense_24_acc: 0.7602 - dense_26_acc: 0.5606 - dense_28_acc: 0.7321 - dense_30_acc: 0.7799 - dense_32_acc: 0.8210 - dense_34_acc: 0.7274 - dense_36_acc: 0.7150 - val_loss: 4.4782 - val_dense_20_loss: 0.4423 - val_dense_22_loss: 0.5134 - val_dense_24_loss: 0.4703 - val_dense_26_loss: 0.6748 - val_dense_28_loss: 0.5055 - val_dense_30_loss: 0.4397 - val_dense_32_loss: 0.3684 - val_dense_34_loss: 0.5310 - val_dense_36_loss: 0.5329 - val_dense_20_acc: 0.7962 - val_dense_22_acc: 0.7442 - val_dense_24_acc: 0.7741 - val_dense_26_acc: 0.5853 - val_dense_28_acc: 0.7558 - val_dense_30_acc: 0.7877 - val_dense_32_acc: 0.8389 - val_dense_34_acc: 0.7327 - val_dense_36_acc: 0.7234\n",
            "\n",
            "Epoch 00009: val_loss improved from 4.48645 to 4.47824, saving model to yelp_weights.h5\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 135s 1s/step - loss: 4.6593 - dense_20_loss: 0.4697 - dense_22_loss: 0.5409 - dense_24_loss: 0.4916 - dense_26_loss: 0.6795 - dense_28_loss: 0.5321 - dense_30_loss: 0.4539 - dense_32_loss: 0.4007 - dense_34_loss: 0.5368 - dense_36_loss: 0.5540 - dense_20_acc: 0.7769 - dense_22_acc: 0.7329 - dense_24_acc: 0.7633 - dense_26_acc: 0.5558 - dense_28_acc: 0.7312 - dense_30_acc: 0.7770 - dense_32_acc: 0.8185 - dense_34_acc: 0.7318 - dense_36_acc: 0.7205 - val_loss: 4.4620 - val_dense_20_loss: 0.4387 - val_dense_22_loss: 0.5128 - val_dense_24_loss: 0.4717 - val_dense_26_loss: 0.6700 - val_dense_28_loss: 0.5049 - val_dense_30_loss: 0.4434 - val_dense_32_loss: 0.3676 - val_dense_34_loss: 0.5217 - val_dense_36_loss: 0.5311 - val_dense_20_acc: 0.8048 - val_dense_22_acc: 0.7472 - val_dense_24_acc: 0.7724 - val_dense_26_acc: 0.5921 - val_dense_28_acc: 0.7575 - val_dense_30_acc: 0.7899 - val_dense_32_acc: 0.8444 - val_dense_34_acc: 0.7413 - val_dense_36_acc: 0.7417\n",
            "\n",
            "Epoch 00010: val_loss improved from 4.47824 to 4.46197, saving model to yelp_weights.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f314486c160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "AAUQAKkrR36A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "319f8307-ba67-4f5c-aa6a-5fc6c6e7e010"
      },
      "cell_type": "code",
      "source": [
        "!ls -l\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 13914288\r\n",
            "drwxr-xr-x 3 root root        4096 Aug  3 16:51 datalab\r\n",
            "-rw-r--r-- 1 root root      174767 Aug  8 11:12 submission.csv\r\n",
            "drwxr-xr-x 2  501 staff   14315520 Oct 30  2015 test_photos\r\n",
            "-rw-r--r-- 1 root root  7102584231 Aug  8 08:33 test_photos.tgz\r\n",
            "-rw-r--r-- 1  504 staff   15193591 Dec 17  2015 test_photo_to_biz.csv\r\n",
            "-rw-r--r-- 1 root root     5019061 Aug  8 08:33 test_photo_to_biz.csv.tgz\r\n",
            "-rw-r--r-- 1  501 staff      28760 Dec 15  2015 train.csv\r\n",
            "-rw-r--r-- 1 root root        7287 Aug  8 08:33 train.csv.tgz\r\n",
            "drwxr-xr-x 2  501 staff   14131200 Oct 30  2015 train_photos\r\n",
            "-rw-r--r-- 1 root root  7026724672 Aug  8 08:29 train_photos.tgz\r\n",
            "-rw-r----- 1  501 staff    2698404 Dec 14  2015 train_photo_to_biz_ids.csv\r\n",
            "-rw-r--r-- 1 root root     1171455 Aug  8 08:33 train_photo_to_biz_ids.csv.tgz\r\n",
            "-rw-r--r-- 1 root root    66147176 Aug  8 11:56 yelp_weights.h5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kjCjEvERHi9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KKq4yC4f-fsd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Получаем предсказания"
      ]
    },
    {
      "metadata": {
        "id": "jdtYddbb-fsd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('yelp_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9JK7mAgXOXwu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b692d1e9-760f-4b57-bf94-f9237470f9d6"
      },
      "cell_type": "code",
      "source": [
        "len(test_photos_df)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1190225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "qno4tpdy-fsd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TestSequence(keras.utils.Sequence):\n",
        "    \"\"\" Класс для чтения батча \"\"\"\n",
        "    def __init__(self, df, batch_size):\n",
        "        self._df = df\n",
        "        self._batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self._df) / float(self._batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        result = []\n",
        "        sample = self._df[idx * self._batch_size:(idx + 1) * self._batch_size]\n",
        "        for _, row in sample.iterrows():\n",
        "            result.append(get_image('test_photos', row['photo_id']))\n",
        "        return np.array(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TO9x2bWfqe1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fbaff1da-9688-4f85-ef31-01a638b91839"
      },
      "cell_type": "code",
      "source": [
        "test_photos_df.head()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>photo_id</th>\n",
              "      <th>business_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>317818</td>\n",
              "      <td>003sg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30679</td>\n",
              "      <td>003sg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>455084</td>\n",
              "      <td>003sg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>371381</td>\n",
              "      <td>003sg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86224</td>\n",
              "      <td>003sg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   photo_id business_id\n",
              "0    317818       003sg\n",
              "1     30679       003sg\n",
              "2    455084       003sg\n",
              "3    371381       003sg\n",
              "4     86224       003sg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "2V2NLfwy-fss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "302bfd15-3165-48d7-ea0e-b9e7268eaf78"
      },
      "cell_type": "code",
      "source": [
        "# читаем данные параллельно в 4потока и применяем модель\n",
        "preds = model.predict_generator(TestSequence(test_photos_df, batch_size=100), workers=4, verbose=1)\n",
        "\n",
        "   "
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11903/11903 [==============================] - 12727s 1s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5V0Wo4pP-fss",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_photos_df['labels'] = [[float(preds[j][i]) for j in range(9)] \n",
        "                            for i in range(len(test_photos_df))] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_K0h6lJE-fss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a2c81d1b-351c-4a1c-a0c3-d759539c8fd1"
      },
      "cell_type": "code",
      "source": [
        "test_photos_df.head()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>photo_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>317818</td>\n",
              "      <td>003sg</td>\n",
              "      <td>[0.20483800768852234, 0.467350572347641, 0.522...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30679</td>\n",
              "      <td>003sg</td>\n",
              "      <td>[0.3618176579475403, 0.49222323298454285, 0.40...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>455084</td>\n",
              "      <td>003sg</td>\n",
              "      <td>[0.2874740958213806, 0.33303380012512207, 0.29...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>371381</td>\n",
              "      <td>003sg</td>\n",
              "      <td>[0.1992282122373581, 0.5290882587432861, 0.573...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86224</td>\n",
              "      <td>003sg</td>\n",
              "      <td>[0.04263046011328697, 0.9716522097587585, 0.98...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   photo_id business_id                                             labels\n",
              "0    317818       003sg  [0.20483800768852234, 0.467350572347641, 0.522...\n",
              "1     30679       003sg  [0.3618176579475403, 0.49222323298454285, 0.40...\n",
              "2    455084       003sg  [0.2874740958213806, 0.33303380012512207, 0.29...\n",
              "3    371381       003sg  [0.1992282122373581, 0.5290882587432861, 0.573...\n",
              "4     86224       003sg  [0.04263046011328697, 0.9716522097587585, 0.98..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "YadW8DeG-fs9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "business_df = test_photos_df.groupby('business_id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uI5iCtc--fs9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = []\n",
        "for k, labels in business_df['labels'].apply(list).iteritems():\n",
        "    labels = np.array(labels).mean(axis=0)\n",
        "    labels = np.where(labels > 0.5)[0]\n",
        "    submission.append((k, ' '.join(map(str, labels))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ynMatAdU-ftJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame(submission, columns=('business_id', 'labels'))\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "# 0.73373"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c8Y3ID3p5TbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f9704ca7-e992-4d15-b3a1-316de621c1dd"
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 13914276\r\n",
            "drwxr-xr-x 3 root root        4096 Aug  3 16:51 datalab\r\n",
            "-rw-r--r-- 1 root root      163329 Aug  8 15:28 submission.csv\r\n",
            "drwxr-xr-x 2  501 staff   14315520 Oct 30  2015 test_photos\r\n",
            "-rw-r--r-- 1 root root  7102584231 Aug  8 08:33 test_photos.tgz\r\n",
            "-rw-r--r-- 1  504 staff   15193591 Dec 17  2015 test_photo_to_biz.csv\r\n",
            "-rw-r--r-- 1 root root     5019061 Aug  8 08:33 test_photo_to_biz.csv.tgz\r\n",
            "-rw-r--r-- 1  501 staff      28760 Dec 15  2015 train.csv\r\n",
            "-rw-r--r-- 1 root root        7287 Aug  8 08:33 train.csv.tgz\r\n",
            "drwxr-xr-x 2  501 staff   14131200 Oct 30  2015 train_photos\r\n",
            "-rw-r--r-- 1 root root  7026724672 Aug  8 08:29 train_photos.tgz\r\n",
            "-rw-r----- 1  501 staff    2698404 Dec 14  2015 train_photo_to_biz_ids.csv\r\n",
            "-rw-r--r-- 1 root root     1171455 Aug  8 08:33 train_photo_to_biz_ids.csv.tgz\r\n",
            "-rw-r--r-- 1 root root    66147176 Aug  8 11:56 yelp_weights.h5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FkWiVMjRcXg3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}